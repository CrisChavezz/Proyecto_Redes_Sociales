# -*- coding: utf-8 -*-
"""Tokenizacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLNFO3MtK6XGIvuLliwcTEKDFKz9NZx9
"""

# Instalar e Importar librerias para dar lectura a los datos y mostrar cada dataframe
# !pip install pandas
import pandas as pd
import json

#-------------Conexi칩n necesaria con Google Drive para manipular las bases de datos-------------
from google.colab import drive
drive.mount('/content/drive')

#---------------- Lectura de datos y Recoleccion de ellos ----------------
# Leemos todos los datos
DFFB = pd.read_json('/content/drive/MyDrive/Proyecto/facebook_data.json', lines=False)
DFIN = pd.read_json('/content/drive/MyDrive/Proyecto/instagram_data.json', lines=False)
DFX = pd.read_json('/content/drive/MyDrive/Proyecto/twitter_data.json', lines=False)

!pip install spacy
!python -m spacy download es_core_news_sm

import spacy

# Cargar el modelo de spaCy para espa침ol
nlp = spacy.load("es_core_news_sm")

# Texto de ejemplo
texto = DFFB['contenido'].to_string()

# Procesar el texto con spaCy
doc = nlp(texto)

# Realizar la tokenizaci칩n y lematizaci칩n, y formatear la salida
print("{0:20}{1:20}".format("--Palabra--", "--Lema--"))
for token in doc:
    print("{0:20}{1:20}".format(token.text, token.lemma_))